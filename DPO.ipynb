{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abinayasankar-co/finetuningworks/blob/main/DPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAtDhAXUjrwY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install transformers trl peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1x0HGIfKZ5r9"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8A_apQwFMLVo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "from trl import DPOTrainer,SFTTrainer\n",
        "from peft import LoraConfig,PeftModel,get_peft_model,prepare_model_for_kbit_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GREmrc7oWiLS"
      },
      "outputs": [],
      "source": [
        "def chatml_format(example):\n",
        "  prompt = \"<|im_start|>\\n You are Supportive AI assistance working. Generate a detailed long answer on it.<|im_end|>\\n <|im_start|>user\\n\"+example[\"instruction\"]+\"<|im_end|>\"\n",
        "  chosen = example[\"chosen_response\"] + '<|im_end|>\\n'\n",
        "  rejected = example[\"rejected_response\"] + '<|im_end|>'\n",
        "\n",
        "  return{\n",
        "      \"prompt\":prompt,\n",
        "      \"chosen\":chosen,\n",
        "      \"rejected\":rejected\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0qYF6EaLtbR"
      },
      "outputs": [],
      "source": [
        "dpo_dataset_dict = {\n",
        "    \"prompt\": [\n",
        "        \"hello\",\n",
        "        \"how are you\",\n",
        "        \"What is your name?\",\n",
        "        \"What is your name?\",\n",
        "        \"Which is the best programming language?\",\n",
        "        \"Which is the best programming language?\",\n",
        "        \"Which is the best programming language?\",\n",
        "    ],\n",
        "    \"chosen\": [\n",
        "        \"hi nice to meet you\",\n",
        "        \"I am fine\",\n",
        "        \"My name is Mary\",\n",
        "        \"My name is Mary\",\n",
        "        \"Python\",\n",
        "        \"Python\",\n",
        "        \"Java\",\n",
        "    ],\n",
        "    \"rejected\": [\n",
        "        \"leave me alone\",\n",
        "        \"I am not fine\",\n",
        "        \"Whats it to you?\",\n",
        "        \"I dont have a name\",\n",
        "        \"Javascript\",\n",
        "        \"C++\",\n",
        "        \"C++\",\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyBCxRG9k5Cv"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"Anthropic/hh-rlhf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdS7s_VJ5Pn9"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24B3GRT_c4YJ"
      },
      "outputs": [],
      "source": [
        "# Define and parse arguments.\n",
        "@dataclass\n",
        "class ScriptArguments:\n",
        "    \"\"\"\n",
        "    The arguments for the DPO training script.\n",
        "    \"\"\"\n",
        "\n",
        "    # data parameters\n",
        "    beta: Optional[float] = field(default=0.1, metadata={\"help\": \"the beta parameter for DPO loss\"})\n",
        "\n",
        "    # training parameters\n",
        "    model_name_or_path: Optional[str] = field(\n",
        "        default=\"../sft/results/final_checkpoint\",\n",
        "        metadata={\"help\": \"the location of the SFT model name or path\"},\n",
        "    )\n",
        "    learning_rate: Optional[float] = field(default=5e-4, metadata={\"help\": \"optimizer learning rate\"})\n",
        "    lr_scheduler_type: Optional[str] = field(default=\"cosine\", metadata={\"help\": \"the lr scheduler type\"})\n",
        "    warmup_steps: Optional[int] = field(default=100, metadata={\"help\": \"the number of warmup steps\"})\n",
        "    weight_decay: Optional[float] = field(default=0.05, metadata={\"help\": \"the weight decay\"})\n",
        "    optimizer_type: Optional[str] = field(default=\"paged_adamw_32bit\", metadata={\"help\": \"the optimizer type\"})\n",
        "\n",
        "    per_device_train_batch_size: Optional[int] = field(default=4, metadata={\"help\": \"train batch size per device\"})\n",
        "    per_device_eval_batch_size: Optional[int] = field(default=1, metadata={\"help\": \"eval batch size per device\"})\n",
        "    gradient_accumulation_steps: Optional[int] = field(\n",
        "        default=4, metadata={\"help\": \"the number of gradient accumulation steps\"}\n",
        "    )\n",
        "    gradient_checkpointing: Optional[bool] = field(\n",
        "        default=True, metadata={\"help\": \"whether to use gradient checkpointing\"}\n",
        "    )\n",
        "\n",
        "    gradient_checkpointing_use_reentrant: Optional[bool] = field(\n",
        "        default=False, metadata={\"help\": \"whether to use reentrant for gradient checkpointing\"}\n",
        "    )\n",
        "\n",
        "    lora_alpha: Optional[float] = field(default=16, metadata={\"help\": \"the lora alpha parameter\"})\n",
        "    lora_dropout: Optional[float] = field(default=0.05, metadata={\"help\": \"the lora dropout parameter\"})\n",
        "    lora_r: Optional[int] = field(default=8, metadata={\"help\": \"the lora r parameter\"})\n",
        "\n",
        "    max_prompt_length: Optional[int] = field(default=512, metadata={\"help\": \"the maximum prompt length\"})\n",
        "    max_length: Optional[int] = field(default=1024, metadata={\"help\": \"the maximum sequence length\"})\n",
        "    max_steps: Optional[int] = field(default=1000, metadata={\"help\": \"max number of training steps\"})\n",
        "    logging_steps: Optional[int] = field(default=10, metadata={\"help\": \"the logging frequency\"})\n",
        "    save_steps: Optional[int] = field(default=100, metadata={\"help\": \"the saving frequency\"})\n",
        "    eval_steps: Optional[int] = field(default=100, metadata={\"help\": \"the evaluation frequency\"})\n",
        "\n",
        "    output_dir: Optional[str] = field(default=\"./results\", metadata={\"help\": \"the output directory\"})\n",
        "    log_freq: Optional[int] = field(default=1, metadata={\"help\": \"the logging frequency\"})\n",
        "    load_in_4bit: Optional[bool] = field(default=True, metadata={\"help\": \"whether to load the model in 4bit\"})\n",
        "    model_dtype: Optional[str] = field(\n",
        "        default=\"float16\", metadata={\"help\": \"model_dtype[float16, bfloat16, float] for loading.\"}\n",
        "    )\n",
        "\n",
        "    # instrumentation\n",
        "    sanity_check: Optional[bool] = field(default=False, metadata={\"help\": \"only train on 1000 samples\"})\n",
        "    report_to: Optional[str] = field(\n",
        "        default=\"wandb\",\n",
        "        metadata={\n",
        "            \"help\": 'The list of integrations to report the results and logs to. Supported platforms are `\"azure_ml\"`,'\n",
        "            '`\"comet_ml\"`, `\"mlflow\"`, `\"neptune\"`, `\"tensorboard\"`,`\"clearml\"` and `\"wandb\"`. '\n",
        "            'Use `\"all\"` to report to all integrations installed, `\"none\"` for no integrations.'\n",
        "        },\n",
        "    )\n",
        "    # debug argument for distributed training\n",
        "    ignore_bias_buffers: Optional[bool] = field(\n",
        "        default=False,\n",
        "        metadata={\n",
        "            \"help\": \"fix for DDP issues with LM bias/mask buffers - invalid scalar type,`inplace operation. See\"\n",
        "            \"https://github.com/huggingface/transformers/issues/22482#issuecomment-1595790992\"\n",
        "        },\n",
        "    )\n",
        "    seed: Optional[int] = field(\n",
        "        default=0, metadata={\"help\": \"Random seed that will be set at the beginning of training.\"}\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4KeVR4mXycD"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(r=16,lora_alpha=16,lora_dropout=0.05,bias='none',task_type=\"CAUSAL_LM\",target_modules =['k_proj','gate_proj','v_proj','up_proj','q_proj','o_proj','drown_proj'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnJvS23FaM3l"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate\n",
        "!pip install -i https://pypi.org/simple/ bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGXFEftpYUqH"
      },
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig,AutoModelForCausalLM\n",
        "import accelerate\n",
        "import bitsandbytes\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\",quantization_config=nf4_config,device_map=\"auto\")\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7etYAWAvfky9"
      },
      "outputs": [],
      "source": [
        "new_model = \"Phi2Model_math\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThkPhRZkdI5L"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "#Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size = 4,\n",
        "    gradient_accumulation_steps =4,\n",
        "    gradient_checkpointing = True,\n",
        "    learning_rate = 5e-5,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    max_steps = 200,\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=1,\n",
        "    output_dir = new_model,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    warmup_steps=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M40INTRkyjeR"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    packing=True,\n",
        "    max_seq_length=None,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0jhvNKHMEs-"
      },
      "outputs": [],
      "source": [
        "dpo_trainer = DPOTrainer(\n",
        "    model,\n",
        "    ref_model = None,\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    peft_config = peft_config,\n",
        "    beta = 0.1,\n",
        "    max_prompt_length = 1024,\n",
        "    max_length = 1536\n",
        ")\n",
        "dpo_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0WU-rVWlWrN"
      },
      "outputs": [],
      "source": [
        "#saving models\n",
        "dpo_trainer.save_pretrained(\"final_checkpoint\")\n",
        "tokenizer.save_pretrained(\"final_checkpoint\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPdA6BkIq5MFAjrGgjoU9tF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}